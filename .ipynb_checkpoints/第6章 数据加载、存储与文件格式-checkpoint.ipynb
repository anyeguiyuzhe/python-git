{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>第6章 数据加载、存储与文件格式</center>\n",
    "\n",
    "## 6.1 读写文本格式的数据\n",
    ">pandas提供了一些用于将表格型数据读取为DataFrame的函数,主要是read_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\文档\\\\Python Scripts\\\\jupyter notebook'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "test=pd.DataFrame(np.array([['a','b','c','d','message'],\\\n",
    "    [1,2,3,4,'hello'],[5,6,7,8,'world'],[9,10,11,12,'foo']]))\n",
    "#保存为csv文件\n",
    "test.to_csv('D:\\\\文档\\\\Python Scripts\\\\data_test\\\\ex1.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取csv文件列名的指定\n",
    "path1=r'D:\\文档\\Python Scripts\\data_test\\ex1.csv'\n",
    "path2=r'D:\\文档\\Python Scripts\\data_test\\ex2.csv'\n",
    "#header的作用是指定列名\n",
    "df1=pd.read_csv(path1,header=0)\n",
    "df2=pd.read_csv(path1,header=1)\n",
    "df3=pd.read_csv(path1,header=None)\n",
    "#当然，你还可以自定义列名，这种情况 header=None\n",
    "name=['Julia','Cindy','Mary','Job','Hack','Navi']\n",
    "df4=pd.read_csv(path1,names=name)\n",
    "#指定某一列为行名\n",
    "df5=pd.read_csv(path1,names=name,index_col='Navi')\n",
    "#如果希望将多个列做成一个层次化的索引，只需要传入由列编号组成的列标即可\n",
    "df6=pd.read_csv('data_test\\\\ex3.csv',header=0,index_col=['key1','key2'])\n",
    "print(df6)\n",
    "#你可以用skiprows跳过文件的第一行、第三行和第四行,如果指定了header，是不会被跳过的\n",
    "#但是这个skiprows貌似是从1开始计数的，不懂\n",
    "df7=pd.read_csv(path,skiprows=[1,3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| 参数 | 说明 |\n",
    "| :-: | :-: |\n",
    "| path | 表示文件系统位置 |\n",
    "| sep | 用于对行中各字段进行拆分的序列或者正则表达式 |\n",
    "| header | 用作列名的行号，默认为0，如果没有，设置为None |\n",
    "| index_col | 用作行索引的列编号或者列名，可以是单个名称或者是列表 |\n",
    "| names | 结合header=None，传入列名 |\n",
    "| skiprows | 需要忽略的行数 |\n",
    "| na_values | 一组用于替换NA的值 |\n",
    "| comment | 用于将注释信息从行尾拆分出去 |\n",
    "| parse_dates | 尝试将数据解析为日期，默认为False，此外还可以指定需要解析的一组列号或者列名 |\n",
    "| keep_data_col | 如果连接多列解析日期，则保持参与连接的列 |\n",
    "| converters | 由列名跟函数之间的映射组成的字典，例如{'foo':f}会对foo列的所有值应用函数'f' |\n",
    "| nrows | 需要读取的行数 |\n",
    "| skip_footer | 需要忽略的函数（从文件末尾处算起） |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逐块读取文本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#逐块读取文本文件\n",
    "#准备大文件\n",
    "import pandas_datareader.data as web\n",
    "code='0700.hk'\n",
    "start='2017-4-4'\n",
    "end='2017-10-10'\n",
    "info=web.get_data_yahoo(code,start,end)\n",
    "info.to_csv('data_test\\\\stock_price.csv',header=1,index=True)\n",
    "\n",
    "#设置pandas的显示\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows=10\n",
    "\n",
    "path=r'data_test\\stock_price.csv'\n",
    "#如果你只想读取几行，通过nrows指定\n",
    "pd.read_csv(path,nrows=10)\n",
    "#read_csv会自动将Date所在的行变为列名\n",
    "df=pd.read_csv(path,index_col='Date')\n",
    "#要逐块读取文件，可以指定chunksize(行数)\n",
    "chunker=pd.read_csv(path,chunksize=100)\n",
    "type(chunker)\n",
    "#TextFileReader对象使你可以根据chunksize对文件进行迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**将数据写出到文本**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "code='600519.ss'\n",
    "start='2017-4-4'\n",
    "end='2017-5-5'\n",
    "info=web.get_data_yahoo(code,start,end)\n",
    "info.to_csv('D:\\\\文档\\\\Python Scripts\\\\data_test\\\\600519ss_price.csv',index=False,na_rep='NULL')\n",
    "#此外，你还可以只写出一部分的列，并以你指定的顺序排列\n",
    "info.to_csv('D:\\\\文档\\\\Python Scripts\\\\data_test\\\\600519ss_price.csv',index=False,na_rep='NULL',columns='High'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv文件的形式有很多，只需定义csv.Dialect的一个子类即可定义出新格式\n",
    "import csv\n",
    "class my_dialect(csv.Dialect):\n",
    "    lineterminator='\\n'\n",
    "    delimiter=';'\n",
    "    quotechar='\"'\n",
    "    quoting=csv.QUOTE_MINIMAL\n",
    "\n",
    "path=r'data_test\\ex7.txt'\n",
    "f=open(path,'r')\n",
    "reader = csv.reader(f, dialect=my_dialect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**JSON数据(JavaScript Object Notation)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    " \"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n",
    " \"pet\": null,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n",
    "              {\"name\": \"Katie\", \"age\": 38,\n",
    "               \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]\n",
    "}\n",
    "\"\"\"\n",
    "#json中的'null'就是python的'None'\n",
    "#loads把json对象转化为Python对象\n",
    "b=json.loads(obj)\n",
    "#dumps把Python对象转换为JSON\n",
    "a=['a','julia','Java','c++']\n",
    "b=json.dumps(a)\n",
    "#如何将JSON对象转化为DataFrame取决于自己的需要\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(b['siblings'],columns=['age'])\n",
    "#pandas.read_json可以将特别格式的JSON数据集转换为Serise或者DataFrame\n",
    "df1=pd.read_json('D:\\\\文档\\\\Python Scripts\\\\data_test\\\\example.json')\n",
    "#把DataFrame输出为json\n",
    "print(df1.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.2 二进制数据格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现数据的高效二进制格式存储最简单的办法之一是使用Python内置的\n",
    "# Pickle序列化。pandas对象都有一个用于将数据以pickle格式保存到\n",
    "# 磁盘上的to_pickle方法：\n",
    "import pandas as pd\n",
    "frame=pd.read_csv('data_test\\\\ex1.csv',index_col='message')\n",
    "frame\n",
    "frame.to_pickle('data_test\\\\frame_pickle')\n",
    "#读取\n",
    "pd.read_pickle('data_test\\\\frame_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HDF5（hierarchical data format）\n",
    "#每个HDF5文件都含有一个文件系统式的节点结构，它使你能够存储多个数据集并支持元数据\n",
    "#支持分块读写\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "frame=pd.DataFrame({'a':np.random.randn(100)})\n",
    "frame2=pd.DataFrame(np.random.randn(30,30))\n",
    "store=pd.HDFStore('data_test\\\\mydata.h5')\n",
    "store['obj1']=frame\n",
    "store['obj2']=frame2\n",
    "store\n",
    "#HDF5文件中的对象可以通过与字典一样的API进行获取\n",
    "store['obj1']\n",
    "store['obj2']\n",
    "#HDFStore支持两种存储模式，'fixed'和'table'，后者更慢，但是支持使用特殊语法进行查询操作\n",
    "#put是store['obj2']=frame的显示版本,允许我们设置其它的选项，比如格式\n",
    "store.put('obj2',frame,format='table')\n",
    "store.select('obj2',where=['index >= 10 and index <= 15','columns=[3,4]'])\n",
    "frame.to_hdf('data_test\\\\mydata.h5','obj3',format='table')\n",
    "pd.read_hdf('data_test\\\\mydata.h5','obj3',where=['index < 5'])\n",
    "#如果需要本地处理海量数据，我建议你好好研究一下PyTables和h5py，看看它们能满足你的\n",
    "# 哪些需求。由于许多数据分析问题都是IO密集型（而不是CPU密集型），利用HDF5这样的\n",
    "# 工具能显著提升应用程序的效率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excel文件处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取Excel文件\n",
    "#pandas的ExcelFile类或者pandas.read_excel函数支持读取存储在Excel文件\n",
    "import pandas as pd\n",
    "xlsx=pd.ExcelFile(r\"D:\\文档\\Python Scripts\\data_test\\hw3data.xlsx\")\n",
    "a=pd.read_excel(xlsx,'日收益率计算')\n",
    "#如果要读取一个文件中的多个表单，创建ExcelFile会更快\n",
    "#但你也可以将文件名直接传递到pandas.read_excel\n",
    "path=r\"D:\\文档\\Python Scripts\\data_test\\hw3data.xlsx\"\n",
    "b=pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写入Excel文件\n",
    "import pandas_datareader.data as web\n",
    "import pandas\n",
    "code='600519.ss'\n",
    "start='2019-4-22'\n",
    "end='2019-4-26'\n",
    "info=web.get_data_yahoo(code,start,end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 web APIs交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "url='https://api.github.com/repos/pandas-dev/pandas/issues'\n",
    "response=requests.get(url).content.decode()\n",
    "a=json.loads(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
